{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZWbUUwqKBdie"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TitusChoi/Novelist_Classification/blob/min/Baseline_Bi_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufcGB_euCc7M"
      },
      "source": [
        "# **데이터 살펴보기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr1zgWURJc7L",
        "outputId": "02260d8f-88d4-4f57-82dc-44d92977353e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yVjZAGCQrzN"
      },
      "source": [
        "!pip install attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmA1Au6CCaC7"
      },
      "source": [
        "import pandas as pd\n",
        "import warnings \n",
        "warnings.filterwarnings(action='ignore')\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import re\n",
        "import gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from keras.layers import LSTM, Bidirectional, Dropout\n",
        "from attention import Attention\n",
        "from keras.optimizers import Adam,Nadam\n",
        "import nltk"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEZtMdB5CaDG"
      },
      "source": [
        "#파일 불러오기\n",
        "train = pd.read_csv('/content/drive/MyDrive/Novelist_Classification/datasets/new_train.csv', encoding = 'utf-8')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Novelist_Classification/datasets/test_x.csv', encoding = 'utf-8')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/Novelist_Classification/datasets/sample_submission.csv', encoding = 'utf-8')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPq0vxJVDS3R"
      },
      "source": [
        "# **전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMUMcInsD80p"
      },
      "source": [
        "#부호를 제거해주는 함수\n",
        "def alpha_num(text):\n",
        "    return re.sub(r'[^A-Za-z0-9 ]', '', text)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf_TGrbKCaDK"
      },
      "source": [
        "# 불용어 제거해주는 함수\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in base_stopwords:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "# 불용어\n",
        "base_stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
        "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
        "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
        "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
        "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
        "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
        "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
        "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
        "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
        "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
        "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUgcc07ADiiU"
      },
      "source": [
        "#전처리 적용\n",
        "train['text'] = train['text'].str.lower()\n",
        "test['text'] = test['text'].str.lower()\n",
        "train['text'] = train['text'].apply(alpha_num).apply(remove_stopwords)\n",
        "test['text'] = test['text'].apply(alpha_num).apply(remove_stopwords)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZdWzRkCDovd"
      },
      "source": [
        "# train test 분리\n",
        "X_train = np.array([x for x in train['text']])\n",
        "X_test = np.array([x for x in test['text']])\n",
        "y_train = np.array([x for x in train['author']])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks1FhSNUHrke"
      },
      "source": [
        "# **모델링**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um6uZK5EDzAm"
      },
      "source": [
        "#파라미터 설정\n",
        "vocab_size = 63728\n",
        "embedding_dim = 16\n",
        "max_length = 500\n",
        "padding_type='post'\n",
        "#oov_tok = \"<OOV>\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvR9_VnTD8L9"
      },
      "source": [
        "#tokenizer에 fit\n",
        "tokenizer = Tokenizer(num_words = vocab_size)#, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FSCNBIYF-n7"
      },
      "source": [
        "# 사전 학습된 glove 불러오고 임베딩 층에 적용시키기 \n",
        "embedding_dict= dict()\n",
        "f = open('/content/drive/MyDrive/Novelist_Classification/embbeding/glove.txt', encoding='utf8')\n",
        "\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 50))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    temp = embedding_dict.get(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnSrd5dIC5RO"
      },
      "source": [
        "# Glove 임베딩 과정\n",
        "vocab = nltk.FreqDist(np.hstack(train['text']))\n",
        "\n",
        "glove = dict()\n",
        "f = open('/content/drive/MyDrive/Novelist_Classification/embbeding/glove.txt',encoding='UTF8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:], dtype='float32')\n",
        "    glove[word] = vector\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2jbc-II80YC"
      },
      "source": [
        "FastText = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Novelist_Classification/embbeding/fasttext.vec')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXh_V23SGAY2"
      },
      "source": [
        "# Fasttext 임베딩 과정\n",
        "FT_embedding_matrix = np.zeros((vocab_size,100))\n",
        "\n",
        "def get_vector(word):\n",
        "    if word in FastText:\n",
        "        return FastText[word]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "for word, idx in word_index.items():\n",
        "    temp = get_vector(word)\n",
        "    if temp is not None:\n",
        "        FT_embedding_matrix[idx] = temp"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQPwyZt0EEHW"
      },
      "source": [
        "#데이터를 sequence로 변환해주고 padding 해줍니다.\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHpJ1yFYemeV"
      },
      "source": [
        "# loss감소가 10번 이상 미발생이면 stop\n",
        "earlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode = 'min', patience=5, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH3ECgJMgrvn"
      },
      "source": [
        "# Bi-LSTM 2계층"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACUbl6xyhDUb"
      },
      "source": [
        "#가벼운 NLP모델 생성\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    Bidirectional(LSTM(64,return_sequences=True,dropout=0.5)),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_XzDkWghDUc",
        "outputId": "a1d34424-efe1-4519-e29f-ea20c8d033c5"
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model summary\n",
        "print(model.summary())\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 500, 16)           1019648   \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 500, 128)          41472     \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 1,160,968\n",
            "Trainable params: 1,160,968\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFUxdQ-chDUg"
      },
      "source": [
        "# fit model\n",
        "num_epochs = 30\n",
        "history = model.fit(train_padded, y_train, \n",
        "                    epochs=num_epochs, verbose=2, \n",
        "                    validation_split=0.2, callbacks = [earlystopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAB4anCGhDUi"
      },
      "source": [
        "#가벼운 NLP모델 생성(Using FastText)\n",
        "model_using_FT = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 100, weights = [FT_embedding_matrix] ,input_length=max_length),\n",
        "    Bidirectional(LSTM(64,return_sequences=True,dropout=0.5)),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynOcbjt4hDUj",
        "outputId": "30368369-b21c-471a-a380-d2d949488cfd"
      },
      "source": [
        "# compile model\n",
        "model_using_FT.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model summary\n",
        "print(model_using_FT.summary())\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 500, 100)          6372800   \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 500, 128)          84480     \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 6,557,128\n",
            "Trainable params: 6,557,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oboOHqHmhDUk"
      },
      "source": [
        "# fit model\n",
        "num_epochs = 30\n",
        "history = model_using_FT.fit(train_padded, y_train, \n",
        "                    epochs=num_epochs, verbose=2, \n",
        "                    validation_split=0.2, callbacks = [earlystopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmhwFYZ2hDUm"
      },
      "source": [
        "#가벼운 NLP모델 생성(Using Glove)\n",
        "model_using_Glove = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 50,weights = [embedding_matrix] ,input_length=max_length),\n",
        "    Bidirectional(LSTM(64,return_sequences=True,dropout=0.5)),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mZm-Tb0hDUn",
        "outputId": "b62f0620-3b69-4485-9446-5f78c1f48353"
      },
      "source": [
        "# compile model\n",
        "model_using_Glove.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model summary\n",
        "print(model_using_Glove.summary())\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 500, 50)           3186400   \n",
            "_________________________________________________________________\n",
            "bidirectional_16 (Bidirectio (None, 500, 128)          58880     \n",
            "_________________________________________________________________\n",
            "bidirectional_17 (Bidirectio (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 3,345,128\n",
            "Trainable params: 3,345,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQno2NRHhDUq"
      },
      "source": [
        "# fit model\n",
        "num_epochs = 30\n",
        "history = model_using_Glove.fit(train_padded, y_train, \n",
        "                    epochs=num_epochs, verbose=2, \n",
        "                    validation_split=0.2, callbacks = [earlystopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nag2ccVggbb"
      },
      "source": [
        "# Bi-LSTM + Attention Mechanism"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2CxfUPZEOu0"
      },
      "source": [
        "#가벼운 NLP모델 생성\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    Bidirectional(LSTM(64,return_sequences=True,dropout=0.3)),\n",
        "    Dropout(0.5),\n",
        "    Attention(32),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxUTpZnPEXJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eade3b9-25e2-4f65-d7e7-4ff19bb69e14"
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model summary\n",
        "print(model.summary())\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 500, 16)           1019648   \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 500, 128)          41472     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 500, 128)          0         \n",
            "_________________________________________________________________\n",
            "last_hidden_state (Lambda)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "attention_score_vec (Dense)  (None, 500, 128)          16384     \n",
            "_________________________________________________________________\n",
            "attention_score (Dot)        (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "attention_weight (Activation (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "context_vector (Dot)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "attention_output (Concatenat (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "attention_vector (Dense)     (None, 128)               32768     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 1,111,304\n",
            "Trainable params: 1,111,304\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51YtSBBiEcMv"
      },
      "source": [
        "# fit model\n",
        "num_epochs = 30\n",
        "history = model.fit(train_padded, y_train, \n",
        "                    epochs=num_epochs, verbose=2, \n",
        "                    validation_split=0.2, callbacks = [earlystopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f_CziRQbntL"
      },
      "source": [
        "#가벼운 NLP모델 생성(Using FastText)\n",
        "model_using_FT = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 100, weights = [FT_embedding_matrix] ,input_length=max_length),\n",
        "    Bidirectional(LSTM(64,return_sequences=True,dropout=0.3)),\n",
        "    Dropout(0.5),\n",
        "    Attention(32),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iqVYWWCeZwB",
        "outputId": "bc26341a-144e-4ab9-fc76-b2d70ff42bcd"
      },
      "source": [
        "# compile model\n",
        "model_using_FT.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model summary\n",
        "print(model_using_FT.summary())\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 500, 100)          6372800   \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 500, 128)          84480     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 500, 128)          0         \n",
            "_________________________________________________________________\n",
            "last_hidden_state (Lambda)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "attention_score_vec (Dense)  (None, 500, 128)          16384     \n",
            "_________________________________________________________________\n",
            "attention_score (Dot)        (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "attention_weight (Activation (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "context_vector (Dot)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "attention_output (Concatenat (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "attention_vector (Dense)     (None, 128)               32768     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 6,507,464\n",
            "Trainable params: 6,507,464\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CGSwTffeh8y"
      },
      "source": [
        "# fit model\n",
        "num_epochs = 30\n",
        "history = model_using_FT.fit(train_padded, y_train, \n",
        "                    epochs=num_epochs, verbose=2, \n",
        "                    validation_split=0.2, callbacks = [earlystopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQbHQ1YxAfm7"
      },
      "source": [
        "#가벼운 NLP모델 생성(Using Glove)\n",
        "model_using_Glove = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 50,weights = [embedding_matrix] ,input_length=max_length),\n",
        "    Bidirectional(LSTM(64,return_sequences=True,dropout=0.3)),\n",
        "    Dropout(0.5),\n",
        "    Attention(32),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBW5Xj5mAhCN",
        "outputId": "79d82c2d-5570-4f72-ca2c-97d05ee817a1"
      },
      "source": [
        "# compile model\n",
        "model_using_Glove.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model summary\n",
        "print(model_using_Glove.summary())\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 500, 50)           3186400   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 500, 128)          58880     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 500, 128)          0         \n",
            "_________________________________________________________________\n",
            "last_hidden_state (Lambda)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "attention_score_vec (Dense)  (None, 500, 128)          16384     \n",
            "_________________________________________________________________\n",
            "attention_score (Dot)        (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "attention_weight (Activation (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "context_vector (Dot)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "attention_output (Concatenat (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "attention_vector (Dense)     (None, 128)               32768     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 3,295,464\n",
            "Trainable params: 3,295,464\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaOGlr3SAjKY"
      },
      "source": [
        "# fit model\n",
        "num_epochs = 30\n",
        "history = model_using_Glove.fit(train_padded, y_train, \n",
        "                    epochs=num_epochs, verbose=2, \n",
        "                    validation_split=0.2, callbacks = [earlystopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jXKoOWIC6g0"
      },
      "source": [
        "# predict values\n",
        "pred = model_using_FT.predict_proba(test_padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4S8eUx5FDFO"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZhbUjhXE3Yr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "daff6f37-fbb1-408a-8232-69889a48ccde"
      },
      "source": [
        "# submission\n",
        "sample_submission[['0','1','2','3','4']] = pred\n",
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19612</th>\n",
              "      <td>19612</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19613</th>\n",
              "      <td>19613</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19614</th>\n",
              "      <td>19614</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19615</th>\n",
              "      <td>19615</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19616</th>\n",
              "      <td>19616</td>\n",
              "      <td>0.244451</td>\n",
              "      <td>0.130629</td>\n",
              "      <td>0.211542</td>\n",
              "      <td>0.27031</td>\n",
              "      <td>0.143069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19617 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index         0         1         2        3         4\n",
              "0          0  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "1          1  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "2          2  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "3          3  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "4          4  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "...      ...       ...       ...       ...      ...       ...\n",
              "19612  19612  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "19613  19613  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "19614  19614  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "19615  19615  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "19616  19616  0.244451  0.130629  0.211542  0.27031  0.143069\n",
              "\n",
              "[19617 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu8Wb207FP-D"
      },
      "source": [
        "sample_submission.to_csv('/content/drive/MyDrive/Novelist_Classification/datasets/submission.csv', index = False, encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}